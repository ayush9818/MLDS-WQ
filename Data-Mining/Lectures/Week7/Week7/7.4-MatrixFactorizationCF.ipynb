{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "990085f2-e53c-4239-9fd9-a28b0ac1fe3a",
   "metadata": {},
   "source": [
    "# Matrix Factorization Based Recommenders\n",
    "\n",
    "Non-negative Matrix Factorization (NMF): This method factors the ratings matrix into two non-negative matrices, which can help with interpretability and handle non-negative data well.\n",
    "\n",
    "Alternating Least Squares (ALS): ALS is an optimization algorithm that iteratively alternates between updating user factors and item factors. It's particularly popular in collaborative filtering recommender systems.\n",
    "\n",
    "Probabilistic Matrix Factorization (PMF): PMF is a probabilistic approach to matrix factorization, where user-item interactions are modeled as Gaussian distributions. It aims to capture uncertainty in the ratings.\n",
    "\n",
    "Weighted Alternating Least Squares (WALS): WALS is an extension of ALS that allows for incorporating side information or weights into the factorization process. It's useful when additional information about users or items is available.\n",
    "\n",
    "Bayesian Personalized Ranking (BPR): BPR is a pairwise learning method that optimizes for ranking tasks rather than prediction accuracy. It's commonly used in recommendation systems where the goal is to recommend items that the user is likely to prefer over others.\n",
    "\n",
    "Deep Learning-based Approaches: Various deep learning architectures, such as autoencoders, recurrent neural networks (RNNs), and convolutional neural networks (CNNs), have been applied to recommendation systems to learn latent representations of users and items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ef3bde3-ff58-49a3-8a0b-ba8b0f1c8b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eea9105-771b-469a-8541-1c54c69eb782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import NMF\n",
    "from implicit.als import AlternatingLeastSquares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dba2872e-5d2d-479b-a317-601134e21fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data (user, item, rating)\n",
    "data = [\n",
    "    {\"user\": \"Alice\", \"item\": \"Guitar\", \"rating\": 5},\n",
    "    {\"user\": \"Alice\", \"item\": \"Drums\", \"rating\": 3},\n",
    "    {\"user\": \"Alice\", \"item\": \"Violin\", \"rating\": 4},  \n",
    "    {\"user\": \"Bob\", \"item\": \"Guitar\", \"rating\": 1},\n",
    "    {\"user\": \"Bob\", \"item\": \"TV\", \"rating\": 5},\n",
    "    {\"user\": \"Bob\", \"item\": \"Radio\", \"rating\": 4},\n",
    "    {\"user\": \"Bob\", \"item\": \"Laptop\", \"rating\": 3}, \n",
    "    {\"user\": \"Charlie\", \"item\": \"Guitar\", \"rating\": 4},\n",
    "    {\"user\": \"Charlie\", \"item\": \"Piano\", \"rating\": 5},\n",
    "    {\"user\": \"Charlie\", \"item\": \"Drums\", \"rating\": 4},\n",
    "    {\"user\": \"Charlie\", \"item\": \"Microphone\", \"rating\": 3}, \n",
    "    {\"user\": \"David\", \"item\": \"Guitar\", \"rating\": 2}, \n",
    "    {\"user\": \"David\", \"item\": \"Violin\", \"rating\": 4},  \n",
    "    {\"user\": \"David\", \"item\": \"Piano\", \"rating\": 3}, \n",
    "    {\"user\": \"David\", \"item\": \"Microphone\", \"rating\": 2}, \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1710afb7-6f07-4e87-a33c-a7bf1e0f8917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to matrix (user x item)\n",
    "users = sorted(set(d['user'] for d in data))\n",
    "items = sorted(set(d['item'] for d in data))\n",
    "\n",
    "user_idx = {u: i for i, u in enumerate(users)}\n",
    "item_idx = {i: j for j, i in enumerate(items)}\n",
    "\n",
    "ratings_matrix = np.zeros((len(users), len(items)))\n",
    "for d in data:\n",
    "    user_id = user_idx[d['user']]\n",
    "    item_id = item_idx[d['item']]\n",
    "    ratings_matrix[user_id, item_id] = d['rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11315c8-4681-4e8a-8f65-0df9942ca274",
   "metadata": {},
   "source": [
    "### Singular Value Decomposition (SVD)\n",
    "\n",
    "SVD decomposes a given data matrix into three matrices: U (orthogonal), Σ (diagonal), and VT (transpose of the conjugate transpose of U).\n",
    "\n",
    "**User Item Interaction X**: represents the user-item interaction data. Each row corresponds to a user, and each column\n",
    "corresponds to an item. E.g.,entry (i, j) = 4.2, it means that user i has given a rating of 4.2 for item j.\n",
    "\n",
    "**Matrix U**: is an orthogonal matrix whose columns are the eigenvectors corresponding to the non-negative\n",
    "singular values. Can be interpreted as a transformation of the original user-item interaction data into a new feature space with simpler structure.\n",
    "\n",
    "**Diagonal Matrix Σ**: contains the singular values, which are non-negative scalars that represent the magnitude\n",
    "of each principal component (column of `U`) in the transformed feature space. \n",
    "\n",
    "**Matrix VT**: is the transpose and conjugate transpose of the matrix $U$. It represents the weights of the original features (columns of `X`) in the transformed feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f92222f-6f4e-44a8-89a3-1084bdb07e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 recommended items for user 'Alice': ['Piano', 'Microphone', 'Drums']\n"
     ]
    }
   ],
   "source": [
    "# Singular Value Decomposition (SVD)\n",
    "U, sigma, Vt = np.linalg.svd(ratings_matrix, full_matrices=False)\n",
    "\n",
    "# Reconstruction of the ratings matrix\n",
    "ratings_matrix_reconstructed = U @ np.diag(sigma) @ Vt\n",
    "\n",
    "# Recommend top N items for a specific user\n",
    "def recommend_items_svd(user_id, ratings_matrix, item_idx, N=3):\n",
    "    user_ratings = ratings_matrix[user_id]\n",
    "    unrated_items_idx = np.where(user_ratings == 0)[0]\n",
    "    predicted_ratings = ratings_matrix_reconstructed[user_id]\n",
    "    top_n_idx = np.argsort(predicted_ratings[unrated_items_idx])[::-1][:N]\n",
    "    top_n_items = [list(item_idx.keys())[list(item_idx.values()).index(idx)] for idx in top_n_idx]\n",
    "    return top_n_items\n",
    "\n",
    "# Example: Recommend top 3 items for user 'Alice'\n",
    "user_id = user_idx['Alice']\n",
    "recommended_items = recommend_items_svd(user_id, ratings_matrix, item_idx)\n",
    "print(f\"Top 3 recommended items for user 'Alice': {recommended_items}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49146fb-8231-4630-b26c-24c4960dbccf",
   "metadata": {},
   "source": [
    "### Non-negative Matrix Factorization (NMF)\n",
    "\n",
    "**Objective**: Aims to factorize a non-negative matrix $V$ into two non-negative matrices $W$ and $H$, such that $V≈WH$. Here, WW represents the user latent factors matrix, and $H$ represents the item latent factors matrix.\n",
    "\n",
    "**Non-negativity Constraint**: Enforces non-negativity on the factor matrices $W$ and $H$. This constraint makes the resulting factorization more interpretable, as it leads to additive parts-based representations.\n",
    "\n",
    "**Loss Function**: Minimizes the Frobenius norm or squared loss between the original matrix $V$ and its approximation $WH$, subject to the non-negativity constraints.\n",
    "\n",
    "**Initialization**: Often uses random initialization or predefined initializations such as singular value decomposition (SVD) or random values drawn from a uniform distribution. The factor matrices are then iteratively updated to minimize the loss function.\n",
    "\n",
    "**Algorithm**: The standard algorithm for NMF is multiplicative update rules, which iteratively updates the factor matrices $W$ and $H$ until convergence. Other algorithms include alternating non-negativity-constrained least squares (ANLS) and projected gradient descent.\n",
    "\n",
    "**Number of Components**: The number of latent factors (components) $k$ is a hyperparameter that needs to be chosen beforehand. It controls the trade-off between approximation accuracy and model complexity.\n",
    "\n",
    "**Interpretability**: NMF produces a parts-based representation, where each row of $W$ corresponds to a user's preferences over latent factors, and each column of HH corresponds to an item's features or characteristics in the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6534f7f-5e70-4700-a515-79a9c517e579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to matrix (user x item)\n",
    "users = sorted(set(d['user'] for d in data))\n",
    "items = sorted(set(d['item'] for d in data))\n",
    "\n",
    "user_idx = {u: i for i, u in enumerate(users)}\n",
    "item_idx = {i: j for j, i in enumerate(items)}\n",
    "\n",
    "user_ids = [user_idx[d['user']] for d in data]\n",
    "item_ids = [item_idx[d['item']] for d in data]\n",
    "ratings = [d['rating'] for d in data]\n",
    "\n",
    "ratings_matrix = csr_matrix((ratings, (user_ids, item_ids)), shape=(len(users), len(items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2f314b9-c427-4833-90b8-db11d7543dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 recommended items for user 'Alice' using NMF: ['Guitar', 'Piano', 'Drums']\n"
     ]
    }
   ],
   "source": [
    "# Non-negative Matrix Factorization (NMF)\n",
    "nmf_model = NMF(n_components=2, init='random', random_state=42)\n",
    "W_nmf = nmf_model.fit_transform(ratings_matrix)\n",
    "H_nmf = nmf_model.components_\n",
    "ratings_matrix_reconstructed_nmf = W_nmf.dot(H_nmf)\n",
    "\n",
    "# Recommend top N items for a specific user using NMF\n",
    "def recommend_items_nmf(user_id, ratings_matrix_reconstructed, item_idx, N=3):\n",
    "    user_ratings = ratings_matrix_reconstructed[user_id]\n",
    "    top_n_idx = np.argsort(user_ratings)[::-1][:N]\n",
    "    top_n_items = [list(item_idx.keys())[list(item_idx.values()).index(idx)] for idx in top_n_idx]\n",
    "    return top_n_items\n",
    "\n",
    "# Example: Recommend top 3 items for user 'Alice' using NMF\n",
    "user_id_alice = user_idx['Alice']\n",
    "recommended_items_alice = recommend_items_nmf(user_id_alice, ratings_matrix_reconstructed_nmf, item_idx)\n",
    "print(f\"Top 3 recommended items for user 'Alice' using NMF: {recommended_items_alice}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9646e99a-821d-493f-8315-6899adade247",
   "metadata": {},
   "source": [
    "### Alternating Least Squares (ALS)\n",
    "\n",
    "**Objective**: ALS aims to factorize a user-item ratings matrix $R$ into two low-rank matrices $U$ (user factors) and $V$ (item factors), such that $R≈UV^T$. Here, UU represents the latent factors of users, and VV represents the latent factors of items.\n",
    "\n",
    "**Alternating Optimization**: ALS alternates between optimizing UU and VV while keeping the other matrix fixed. It iteratively updates one matrix while holding the other constant, and then switches roles.\n",
    "\n",
    "**Least Squares Optimization**: ALS minimizes the least squares error between the observed ratings in $R$ and the predicted ratings $UV^T$. This is typically achieved through alternating least squares optimization, where one matrix is fixed and the other is optimized using least squares optimization.\n",
    "\n",
    "**Regularization**: ALS often incorporates regularization terms to prevent overfitting. Regularization penalizes large values in the factor matrices, encouraging smaller and more generalizable solutions.\n",
    "\n",
    "**Initialization**: ALS can be initialized with random values or with predefined initializations such as SVD. The initial values are then iteratively updated to minimize the least squares error.\n",
    "\n",
    "**Number of Factors**: The number of latent factors is a hyperparameter that needs to be chosen beforehand. It controls the trade-off between approximation accuracy and model complexity.\n",
    "\n",
    "**Implicit Feedback**: ALS can also be used with implicit feedback data, where the absence of a rating does not necessarily imply dislike. In such cases, ALS optimizes for ranking-based objectives, such as maximizing the likelihood of observed interactions.\n",
    "\n",
    "Scalability: ALS is highly parallelizable and can be efficiently implemented on distributed computing platforms. This makes it scalable to large datasets and suitable for real-time recommendation systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3223a21-ab31-48b1-8fc5-e6dc3ce1a18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/implicit/cpu/als.py:95: RuntimeWarning: OpenBLAS is configured to use 12 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n",
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/implicit/utils.py:164: ParameterWarning: Method expects CSR input, and was passed csc_matrix instead. Converting to CSR took 4.410743713378906e-05 seconds\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c03f6c465f64b7b91a2c878c2f60f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 recommended items for user 'Alice' using ALS: ['Laptop', 'Microphone', 'Drums']\n"
     ]
    }
   ],
   "source": [
    "# Alternating Least Squares (ALS)\n",
    "als_model = AlternatingLeastSquares(factors=2, regularization=0.1, iterations=50, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "als_model.fit(ratings_matrix.T)\n",
    "\n",
    "# Get the user and item factors\n",
    "user_factors = als_model.user_factors\n",
    "item_factors = als_model.item_factors\n",
    "\n",
    "# Reconstruct the ratings matrix\n",
    "ratings_matrix_reconstructed = user_factors.dot(item_factors.T)\n",
    "\n",
    "# Recommend top N items for a specific user using ALS\n",
    "def recommend_items_als(user_id, ratings_matrix_reconstructed, item_idx, N=3):\n",
    "    user_ratings = ratings_matrix_reconstructed[user_id]\n",
    "    top_n_idx = np.argsort(user_ratings)[::-1][:N]\n",
    "    top_n_items = [list(item_idx.keys())[list(item_idx.values()).index(idx)] for idx in top_n_idx]\n",
    "    return top_n_items\n",
    "\n",
    "# Example: Recommend top 3 items for user 'Alice' using ALS\n",
    "user_id_alice = user_idx['Alice']\n",
    "recommended_items_alice = recommend_items_als(user_id_alice, ratings_matrix_reconstructed, item_idx)\n",
    "print(f\"Top 3 recommended items for user 'Alice' using ALS: {recommended_items_alice}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
